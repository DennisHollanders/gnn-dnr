description: "Stage 2 HPO for GAT: Hyperparameter tuning with best architecture from Stage 1"
job_name: "GAT-stage2-hyperparameter-tuning"

# Data Configuration
dataset_names: ["train", "validation", "test"]
folder_names: 
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/train"
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/validation"
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/test"
dataset_type: "default"
batching_type: "dynamic"
max_nodes: 20000
max_edges: 50000
train_ratio: 0.85
seed: 0
num_workers: 0

# Model Configuration (fixed for all trials)
model_module: "AdvancedMLP"

# STAGE 2: Fixed Parameters (Best Architecture from Stage 1)
fixed_params:
  # Output Configuration
  output_type: "multiclass"
  num_classes: 2
  
  # Best GAT Architecture from Stage 1
  gnn_type: "GAT"
  gnn_layers: 2
  gat_heads: 2
  gnn_hidden_dim: 384
  gin_eps: 0.0
  
  # Best MLP Architecture from Stage 1
  use_node_mlp: false  # Stage 1 found node MLP not beneficial
  use_edge_mlp: true
  edge_hidden_dims: [64]  # From edge_hidden_dims_0: 64, n_edge_hidden_dims_layers: 1
  
  # Best Switch Head Architecture from Stage 1
  switch_head_type: "mlp"
  switch_head_layers: 2
  switch_attention_heads: 1
  
  # General Configuration (keep fixed)
  activation: "leaky_relu"
  use_batch_norm: true
  use_residual: true
  use_skip_connections: true
  pooling: "add"
  
  # Physics Configuration (keep fixed)
  use_gated_mp: true
  use_phyr: false
  enforce_radiality: false
  
  # Training Configuration (keep some fixed)
  epochs: 200  # Increase for final training
  patience: 25  # Increase patience for final training
  criterion_name: "FocalLoss"

# STAGE 2: HYPERPARAMETER TUNING SEARCH SPACE
search_space:
  # Training Hyperparameters
  learning_rate:
    search_type: "float"
    min: 0.0001
    max: 0.01
    log: true
  
  weight_decay:
    search_type: "float"
    min: 0.000001
    max: 0.001
    log: true
  
  dropout_rate:
    search_type: "float"
    min: 0.0
    max: 0.5
  
  # GAT-specific hyperparameters
  gat_dropout:
    search_type: "float"
    min: 0.0
    max: 0.5
  
  # Physics Loss Hyperparameters
  lambda_phy_loss:
    search_type: "float"
    min: 0.1
    max: 2.0
  
  lambda_mask:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  
  lambda_connectivity:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  
  lambda_radiality:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  
  # Loss scaling strategy
  loss_scaling_strategy:
    search_type: "categorical"
    choices: ["fixed", "adaptive", "adaptive_ratio"]
  
  normalization_type:
    search_type: "categorical"
    choices: ["adaptive", "standard", "robust"]
  
  # Batch size optimization
  batch_size:
    search_type: "categorical"
    choices: [32, 64, 128, 256]

# Logging
wandb: true
wandb_project: "GAT_HPO_Stage2"