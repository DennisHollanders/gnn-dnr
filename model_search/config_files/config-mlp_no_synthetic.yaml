description: "GIN model with hyperparameter optimization"
job_name: "None"


# Data Configuration
dataset_names: ["train", "validation", "test"]
folder_names:
  - "data\\split_datasets_without_synthetic\\train"
  - "data\\split_datasets_without_synthetic\\validation"
  - "data\\split_datasets_without_synthetic\\test"
dataset_type: "default"
batching_type: "dynamic"
max_nodes: 20000
max_edges: 50000
train_ratio: 0.85
seed: 0
num_workers: 0

# Model Configuration
model_module: "AdvancedMLP"
model_kwargs:
  # GIN Configuration
  gnn_type: "GIN"
  gin_mlp_layers: 3
  gin_eps: 0.06118747565904727
  gin_train_eps: false
  gnn_layers: 1
  gnn_hidden_dim_multiple: 302

  # Edge MLP
  use_edge_mlp: true
  edge_hidden_dims: [128, 256, 128]
  n_edge_hidden_dims_layers: 3

  # Node MLP
  use_node_mlp: true
  node_hidden_dims: [256, 512,256, 128]
  n_node_hidden_dims_layers: 4

  # General Configuration
  activation: "relu"
  dropout_rate: 0.0013447489600537238
  use_batch_norm: true
  use_residual: true
  use_skip_connections: true
  pooling: "add"

  # Switch Head
  switch_head_type: "mlp"
  switch_head_layers: 4

  # Physics
  use_gated_mp: true
  use_phyr: false
  lambda_phy_loss: 0.9634733268065652
  lambda_connectivity: 0.031023696908473272
  lambda_radiality: 0.0036467753703689383

  # Loss & Optimization
  loss_scaling_strategy: "adaptive_magnitude"
  criterion_name: "CrossEntropyLoss"
  
  weight_decay: 3.1083921460064515e-05
learning_rate: 0.0009708944531483163
weight_decay: 3.1083921460064515e-05
criterion_name: "CrossEntropyLoss"
# Training Configuration
batch_size: 128
epochs: 200
patience: 20

# Output Configuration
output_type: "multiclass"
num_classes: 2

# Logging
wandb_project: "GIN_HPO"
wandb: true
