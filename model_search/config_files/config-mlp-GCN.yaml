description: "GCN model with hyperparameter optimization"
job_name: "best-GCN"

# Data Configuration
dataset_names: ["train", "validation", "test"]
folder_names:
  - "data\\split_datasets\\train"
  - "data\\split_datasets\\validation"
  - "data\\split_datasets\\test"
dataset_type: "default"
batching_type: "dynamic"
max_nodes: 20000
max_edges: 50000
batch_size: 128
train_ratio: 0.85
seed: 0
num_workers: 0

# Training Configuration
learning_rate: 0.0004029976643955208
weight_decay: 8.701448752941287e-06
epochs: 200
patience: 20
criterion_name: "FocalLoss"

# Physics Loss Configuration (used in training loop)
lambda_connectivity: 0.030008364467226708
lambda_mask: 0.46073466660568596
lambda_phy_loss: 7.58031640466716
lambda_radiality: 0.012630952201391193
# loss_scaling_strategy: "fixed"
#normalization_type: "simple"


# Model Configuration
model_module: "AdvancedMLP"
model_kwargs:
  # Output Configuration
  output_type: "multiclass"
  num_classes: 2
  
  # GNN Configuration
  gnn_type: "GCN"
  gnn_layers: 4
  gnn_hidden_dim: 128
  gin_eps: 0.0
  gat_heads: 0
  gat_dropout: 0.0

  # MLP Configuration
  use_node_mlp: True
  node_hidden_dims: [64]
  use_edge_mlp: true
  edge_hidden_dims: [32, 64, 128]

  # General Configuration
  activation: "leaky_relu"
  dropout_rate: 0.014909725001545145
  use_batch_norm: true
  use_residual: false
  use_skip_connections: true

  # Switch Head Configuration
  switch_head_type: "mlp"
  switch_head_layers: 3
  switch_attention_heads: 0

  # Physics Configuration
  use_gated_mp: true
  use_phyr: false
  enforce_radiality: false  

# Logging
wandb: true
wandb_project: "GIN_HPO"