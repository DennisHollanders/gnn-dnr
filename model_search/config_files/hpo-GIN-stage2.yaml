description: "Stage 2 HPO for GIN: Hyperparameter tuning with best architecture from Stage 1"
job_name: "GIN-stage2-hyperparameter-tuning"

# --- Data Configuration ---
dataset_names: ["train", "validation", "test"]
folder_names: 
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/train"
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/validation"
  - "/vast.mnt/home/20174047/gnn-dnr/data/split_datasets/test"
dataset_type: "default"
batching_type: "dynamic"
max_nodes: 20000
max_edges: 50000
train_ratio: 0.85
seed: 0
num_workers: 0

# --- Model Configuration ---
model_module: "AdvancedMLP"

# --- STAGE 2: Fixed Parameters (Best Architecture from Stage 1) ---
fixed_params:
  # Output Configuration
  output_type: "multiclass"
  num_classes: 2
  
  # Best GIN Architecture from Stage 1
  gnn_type: "GIN"
  gnn_layers: <PLACEHOLDER> # e.g., 3
  gnn_hidden_dim: <PLACEHOLDER> # e.g., 256
  gin_mlp_layers: <PLACEHOLDER> # e.g., 2
  gin_train_eps: <PLACEHOLDER> # e.g., true
  activation: <PLACEHOLDER> # e.g., "leaky_relu"
  
  # Best MLP Architecture from Stage 1
  node_hidden_dims: [<PLACEHOLDER>] # e.g., [256, 128] or []
  edge_hidden_dims: [<PLACEHOLDER>] # e.g., [128, 64] or []
  
  # Best Switch Head Architecture from Stage 1
  switch_head_type: <PLACEHOLDER> # e.g., "mlp"
  switch_head_layers: <PLACEHOLDER> # e.g., 2
  switch_attention_heads: <PLACEHOLDER> # e.g., 4
  
  # Best General Configuration from Stage 1
  use_batch_norm: <PLACEHOLDER> # e.g., true
  use_residual: <PLACEHOLDER> # e.g., true
  use_skip_connections: <PLACEHOLDER> # e.g., false
  use_gated_mp: <PLACEHOLDER> # e.g., true
  
  # Default GAT params
  gat_heads: 0
  gat_dropout: 0.0

  # Training Configuration (partially fixed)
  epochs: 200
  patience: 25
  criterion_name: "FocalLoss"

# --- STAGE 2: HYPERPARAMETER TUNING SEARCH SPACE ---
search_space:
  # Training Hyperparameters
  learning_rate:
    search_type: "float"
    min: 0.0001
    max: 0.01
    log: true
  weight_decay:
    search_type: "float"
    min: 1.0e-6
    max: 1.0e-3
    log: true
  dropout_rate:
    search_type: "float"
    min: 0.0
    max: 0.5
  
  # GIN-specific hyperparameters
  gin_eps:
    search_type: "float"
    min: 0.0
    max: 0.5

  # Physics Loss Hyperparameters
  lambda_phy_loss:
    search_type: "float"
    min: 0.1
    max: 2.0
  lambda_mask:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  lambda_connectivity:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  lambda_radiality:
    search_type: "float"
    min: 0.001
    max: 0.1
    log: true
  
  # Strategy Hyperparameters
  loss_scaling_strategy:
    search_type: "categorical"
    choices: ["fixed", "adaptive_ratio", "adaptive_magnitude"]
  normalization_type:
    search_type: "categorical"
    choices: ["adaptive", "simple", "injection_scale", "per_node", "paper_based"]
  
  # Batch size
  batch_size:
    search_type: "categorical"
    choices: [32, 64, 128, 256]
