# ====================================================================
# hpo-GIN-stage2.yaml
# Stage 2: Fine-tuning Best Architecture (16 dimensions)
# ====================================================================

# Basic model configuration
model_module: "AdvancedMLP"
dataset_names: ["train", "validation", "test"]
folder_names:
  - "data\\split_datasets\\train"
  - "data\\split_datasets\\validation"
  - "data\\split_datasets\\test"
dataset_type: "default"
batching_type: "dynamic"

# Fixed parameters for Stage 2
fixed_params:
  # Core GNN settings
  gnn_type: "GIN"  
  use_node_mlp: true
  use_edge_mlp: true
  
  # Data settings
  batch_size: 32
  max_nodes: 1000
  max_edges: 5000
  train_ratio: 0.85
  num_workers: 0
  seed: 42
  
  # Training settings
  epochs: 200
  patience: 100
  use_phyr: false
  
  # Output settings 
  output_type: "binary"
  num_classes: 2  
  wandb_project: "GIN_HPO_Stage2"

  # BEST ARCHITECTURE FROM STAGE 1 - REPLACE WITH ACTUAL RESULTS
  # TODO: Replace these placeholders with actual best values from Stage 1
  gnn_layers: PLACEHOLDER_BEST_GNN_LAYERS
  gnn_hidden_dim: PLACEHOLDER_BEST_GNN_HIDDEN_DIM
  gin_eps: PLACEHOLDER_BEST_GIN_EPS
  gin_train_eps: PLACEHOLDER_BEST_GIN_TRAIN_EPS
  gin_mlp_layers: PLACEHOLDER_BEST_GIN_MLP_LAYERS
  node_mlp_layers: PLACEHOLDER_BEST_NODE_MLP_LAYERS
  node_mlp_dim: PLACEHOLDER_BEST_NODE_MLP_DIM
  edge_mlp_layers: PLACEHOLDER_BEST_EDGE_MLP_LAYERS
  edge_mlp_dim: PLACEHOLDER_BEST_EDGE_MLP_DIM
  switch_head_type: PLACEHOLDER_BEST_SWITCH_HEAD_TYPE

# Stage 2 Search Space - 16 dimensions for fine-tuning
search_space:
  # 1. Learning rate 
  learning_rate:
    search_type: "float"
    min: 0.00001
    max: 0.01
    log: true

  # 2. Weight decay 
  weight_decay:
    search_type: "float"
    min: 0.000001
    max: 0.001
    log: true

  # 3. Dropout rate
  dropout_rate:
    search_type: "float"
    min: 0.0
    max: 0.4

  # 4. Activation function
  activation:
    search_type: "categorical"
    choices: ["relu", "gelu", "tanh", "elu", "leaky_relu", "sigmoid"]

  # 5. Use batch normalization
  use_batch_norm:
    search_type: "categorical"
    choices: [true, false]

  # 6. Use residual connections
  use_residual:
    search_type: "categorical"
    choices: [true, false]

  # 7. Use skip connections
  use_skip_connections:
    search_type: "categorical"
    choices: [true, false]

  # 8. Switch head layers
  switch_head_layers:
    search_type: "int"
    min: 2
    max: 5

  # 9. Criterion/Loss function
  criterion_name:
    search_type: "categorical"
    choices: ["MSELoss", "CrossEntropyLoss", "WeightedBCELoss", "FocalLoss"]

  # 10. Normalization type
  normalization_type:
    search_type: "categorical"
    choices: ["none", "simple", "injection_scale", "adaptive", "per_node"]

  # 11. Loss scaling strategy
  loss_scaling_strategy:
    search_type: "categorical"
    choices: ["fixed", "adaptive_ratio", "adaptive_magnitude", "uncertainty_weighted"]

  # 12. Use gated message passing
  use_gated_mp:
    search_type: "categorical"
    choices: [true, false]

  # 15. Physics loss weight
  lambda_phy_loss:
    search_type: "float"
    min: 0.01
    max: 1.0
    log: true

  # 16. Graph pooling method
  pooling:
    search_type: "categorical"
    choices: ["mean", "max", "add"]